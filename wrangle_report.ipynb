{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Report on Twitter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went through mainly three steps to get the final clean twitter archive master dataset:\n",
    "\n",
    "1. **Gather**\n",
    "2. **Assess**\n",
    "3. **Clean**\n",
    "\n",
    "<br>\n",
    "\n",
    "In the **Gather** phase, we collected data from three different sources:\n",
    "\n",
    "- `image-predictions.tsv`. This is a tab-separated file stored on Udacity's servers and we download it programmatically using python's `requests` library via a url.\n",
    "\n",
    "\n",
    "- `twitter-archive-enhanced.csv`. This is a comma-separated file on hand. We only need to load it in panda's DataFrame.\n",
    "\n",
    "\n",
    "- `tweet_json.txt`. We get this file by a little bit more efforts than the other two as it does not intuitively exist. First we must extract the tweet ids from `image-predictions.tsv`. Then use the ids to acquire the information (i.e. `retweet_count` and `favorite_count`) we need using python's library [Tweepy](https://www.tweepy.org/) to access Twitter's API. Finally we parse the returned results (which is formatted as `JSON`) and extract the information of interest to make our DataFrame.\n",
    "\n",
    "In the **Assess** phase, we mainly evaluate the data we collected from the **Gather** phase and analyze their quality and tidiness issues both manually and programmatically. In total we found 8 quality issues and 2 tidiness issues although there could be more to be explored. For the final presentation of insights, we found the following issues:\n",
    "\n",
    "**Quality Issues**\n",
    "\n",
    "   **`twi_archive` table**\n",
    "\n",
    "   1. Some rows have values in columns like `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp` which denote that this is a retweet or reply (should be null actually according to the **projejct requirements or Key Points**: \"You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\")\n",
    "   2. `tweet_id` is integer not string\n",
    "   3. `timestamp` is object (string) not datetime object; `retweeted_status_timestamp` is the same.\n",
    "   4. `in_reply_to_user_id` and `retweeted_status_id` are float not string\n",
    "   5. `rating_numerator` and `rating_denominator` are integer not float\n",
    "   6. Incorrect dog names in under `name` (e.g. \"a\" (tweet_id:`881536004380872706`), \"my\" (tweet_id: `765395769549590528`), \"one\" (tweet_id: `755206590534418437`, `748575535303884801`), \"his\" (tweet_id: `748692773788876800`) ...)\n",
    "   7. Incorrect ratings (i.e. **75/10** (actually should be `9.75/10` from tweet_id: `786709082849828864`); rating_denominator is **0** (which is invalid from tweet_id: `835246439529840640`))\n",
    "\n",
    "\n",
    "   **`img_pred` table**\n",
    "\n",
    "   8. `tweet_id` is integer not string\n",
    "\n",
    "\n",
    "   **`twi_count` table**\n",
    "\n",
    "   9. `tweet_id` is integer not string\n",
    "   \n",
    "   \n",
    "**Data Tidiness Issues**\n",
    "\n",
    "   1. In `twi_archive` table, columns `doggo`, `floofer`, `pupper`, `puppo` distributed in four columns but should be in only one column for one feature instead, namely `dog_stage`.\n",
    "\n",
    "   2. Data are distributed in three tables which should be merged as an integrated one.\n",
    "\n",
    "<br>\n",
    "   \n",
    "In the **Clean** phase, we use various functions in the versatile `pandas` library to accomplish our cleaning work and generate our final clean master dataset and store it as `twitter_archive_master.csv`.\n",
    "\n",
    "Based on the clean master dataset, we came up with five interesting insights:\n",
    "\n",
    "   **1. What are the TOP 10 Tweets favored by most users? And how about the retweets?**\n",
    "   \n",
    "   **2. What are the most common dog names?**\n",
    "\n",
    "   **3. What are the most common dog_stage in these tweets?**\n",
    "\n",
    "   **4. What is the ratings distributed like?**\n",
    "\n",
    "   **5. What are the most common breeds found by the neural network?**\n",
    "\n",
    "As per each question, we analyze and visualize them in the `act_report.ipynb` or  `act_report.html`.\n",
    "\n",
    "<br>\n",
    "\n",
    "As shown above is the general workflow on how we wrangle and cleanse the twitter dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
